{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074d2c4-131b-4395-8316-595a3287382f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install labelbox[data]\n",
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b3151-72f5-49e7-864f-fa557eba4615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import labelbox as lb\n",
    "import labelbox.types as lb_types\n",
    "import uuid\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "# Setup client\n",
    "with open(\"labelbox_api_key.txt\",\"r\") as f:\n",
    "    API_KEY = f.read().strip()\n",
    "client = lb.Client(api_key=API_KEY)\n",
    "\n",
    "# Get ontology\n",
    "print(\"===ONTOLOGY DETAILS===\")\n",
    "ontology = client.get_ontology(\"clqo6bd8v0jc407ybc1r9ehlb\")\n",
    "print(\"Name: \", ontology.name)\n",
    "tools = ontology.tools()\n",
    "\n",
    "# for tool in tools:\n",
    "#   print(tool)\n",
    "\n",
    "# Get project\n",
    "print(\"\\n===PROJECT DETAILS===\")\n",
    "PROJECT_ID = 'clqoh3ylw1o8s070hd6ch5z7o' # WHOI RSI USVI Fish\n",
    "# PROJECT_ID = 'clqo7auln0mpo07wphorp0t2e' # Test WHOI RSI USVI Fish\n",
    "project = client.get_project(PROJECT_ID)\n",
    "print(\"Name: \", project.name)\n",
    "\n",
    "# Get dataset\n",
    "DATASET_ID = \"clqh7v7qi001r07886j6aws7i\"\n",
    "dataset = client.get_dataset(DATASET_ID)\n",
    "print(\"\\n===DATASET DETAILS===\")\n",
    "print(\"Name: \", dataset.name)\n",
    "\n",
    "# Dataset parameters\n",
    "species_level = True # Extract species-level data (otherwise single-class \"fish\"), use with data_rows_done_only\n",
    "data_rows_done_only = True # Only utilize data rows that have undergone species review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b028c-34d6-4f40-b9e8-f7ddfc2cfe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate species labels for YOLO class formatting\n",
    "classes_option = {}\n",
    "classes_enum = {}\n",
    "ordered_class_names = []\n",
    "\n",
    "classes_option[\"fish\"] = {\"label\": \"Fish\", \"value\": \"fish\"}\n",
    "classes_enum[\"fish\"] = 0\n",
    "ordered_class_names.append(\"fish\")\n",
    "\n",
    "if species_level:\n",
    "    for option_num, option in enumerate(tools[0].classifications[0].options):\n",
    "        classes_option[option.value] = option\n",
    "        classes_enum[option.value] = len(ordered_class_names)\n",
    "        ordered_class_names.append(option.value)\n",
    "#print(\"Classes: \", len(ordered_class_names))\n",
    "print(list(zip(classes_enum.values(), classes_enum.keys())))\n",
    "print(ordered_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6fe507-3cae-42e0-b7d2-402e83a2354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recommended to download JSON from Labelbox using the Browser Interface\n",
    "# TODO: Verify whether or not this includes interpolated (non-keyframed) data\n",
    "\n",
    "# Extracts fish labels from labelbox json file and converts them into YOLO format\n",
    "# Assumes the global_key from labelbox matches the directory structure of the images\n",
    "# Fish class is assumed as 0\n",
    "\n",
    "dry_run = False\n",
    "save_images = False\n",
    "make_copy = True # Good for creating sub-datasets (like species-classifier, since not all videos have been labelled to that level)\n",
    "\n",
    "import json\n",
    "import jsonlines\n",
    "import os\n",
    "from pathlib import Path\n",
    "from bbox_utils import *\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# json_path = \"/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/Labelbox-Export-WHOI-RSI-USVI-Fish-detect-and-track - 6_11_2024.ndjson\"\n",
    "# image_root = Path(\"/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/whoi-rsi-fish-detection-yolo-dataset/images\")\n",
    "# label_output_root = Path(\"/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/whoi-rsi-fish-detection-yolo-dataset/labels\")\n",
    "# label_output_root = Path(\"/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/whoi-rsi-fish-detection-yolo-dataset/labels_species_only\")\n",
    "# label_output_root = Path(\"/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/whoi-rsi-fish-detection-yolo-dataset/test_labels\")\n",
    "# image_output_root = Path(\"/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/whoi-rsi-fish-detection-yolo-dataset/test_images\")\n",
    "\n",
    "# For species-level datasets\n",
    "# label_output_root = Path(\"/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/whoi-rsi-fish-detection-species-yolo-dataset/labels\")\n",
    "# image_output_root = Path(\"/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/whoi-rsi-fish-detection-species-yolo-dataset/images\")\n",
    "\n",
    "# Local\n",
    "json_path = \"/media/data/warp_data/wrsi-datasets/Labelbox-Export-WHOI-RSI-USVI-Fish-detect-and-track - 6_11_2024.ndjson\"\n",
    "image_root = Path(\"/media/data/warp_data/wrsi-datasets/whoi-rsi-fish-detection-yolo-dataset/images\")\n",
    "\n",
    "label_output_root = Path(\"/media/data/warp_data/wrsi-datasets/whoi-rsi-fish-detection-species-yolo-dataset/labels\")\n",
    "image_output_root = Path(\"/media/data/warp_data/wrsi-datasets/whoi-rsi-fish-detection-species-yolo-dataset/images\")\n",
    "\n",
    "list_of_videos = []\n",
    "stats = {}\n",
    "\n",
    "# with open(json_path, \"r\") as f:\n",
    "with jsonlines.open(json_path, \"r\") as json_file:\n",
    "\n",
    "    # Iterate through each video in the JSON file\n",
    "    for i, datarow in tqdm(enumerate(json_file)):\n",
    "        global_key = datarow[\"data_row\"][\"global_key\"]\n",
    "        \n",
    "        # Skip datarows that are not DONE, if applicable (usually used alongside species-level)\n",
    "        project_status = datarow[\"projects\"][PROJECT_ID][\"project_details\"][\"workflow_status\"]\n",
    "        if data_rows_done_only and not project_status == \"DONE\":\n",
    "            print(\"Skipping not done: \", global_key)\n",
    "            continue\n",
    "\n",
    "        img_sz = (datarow[\"media_attributes\"][\"width\"], datarow[\"media_attributes\"][\"height\"])\n",
    "        \n",
    "        # Video path\n",
    "        vid_path = Path(global_key)\n",
    "        rel_vid_path = vid_path.parent / \"_\".join(vid_path.stem.split(\"_\")[:-1])\n",
    "\n",
    "        # Grab frame labels\n",
    "        try:\n",
    "            frames_json = datarow[\"projects\"][PROJECT_ID][\"labels\"][0][\"annotations\"][\"frames\"]\n",
    "        except:\n",
    "            # No labels in this video, so continue\n",
    "            print(\"Skipping \", global_key, \" has no labels\")\n",
    "            continue\n",
    "\n",
    "        # Iterate through frames\n",
    "        frame_count = datarow[\"media_attributes\"][\"frame_count\"]\n",
    "        \n",
    "        for frame_id in range(frame_count):\n",
    "            img_name = \"frame_%03d\"%(int(frame_id))\n",
    "            img_path = image_root / rel_vid_path / (img_name + \".png\")\n",
    "            output_path = label_output_root / rel_vid_path / (img_name + \".txt\")  \n",
    "\n",
    "            if make_copy:\n",
    "                output_img_path = image_output_root / rel_vid_path / (img_name + \".png\")\n",
    "\n",
    "                if not dry_run:\n",
    "                    os.makedirs(output_img_path.parent, exist_ok=True)\n",
    "                    shutil.copy2(img_path, output_img_path)\n",
    "                else:\n",
    "                    print(\"Copying \", img_path, \" to \", output_img_path)\n",
    "                \n",
    "            # Verify this image exists\n",
    "            assert img_path.exists(), f\"Image not found {img_path}\"\n",
    "            \n",
    "            os.makedirs(output_path.parent, exist_ok=True)\n",
    "            \n",
    "            # Make label file, overwrite if already there\n",
    "            open(output_path, \"w\")\n",
    "\n",
    "            # No labels in this frame, so continue\n",
    "\n",
    "            # Labelbox frames are 1-indexed, everywhere else is 0-indexed\n",
    "            lblbox_frame_id = frame_id + 1\n",
    "            if str(lblbox_frame_id ) in frames_json:\n",
    "                frame_data = frames_json[str(lblbox_frame_id)]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            for object_id, object_data in frame_data[\"objects\"].items():\n",
    "                lbl_bbox = object_data[\"bounding_box\"]\n",
    "                \n",
    "                if species_level:\n",
    "                    if len(object_data[\"classifications\"]) > 0:\n",
    "                        class_name = object_data[\"classifications\"][0][\"radio_answer\"][\"value\"]\n",
    "                        label = classes_enum[class_name]\n",
    "                    else:\n",
    "                        label = 0\n",
    "                else:\n",
    "                    label = 0\n",
    "\n",
    "                yolo_bbox = list(labelbox2yolo_bbox(lbl_bbox, img_sz))\n",
    "                yolo_bbox.insert(0, label)\n",
    "                \n",
    "                with open(output_path, \"a\") as f:\n",
    "                    if not dry_run:\n",
    "                        f.write(\" \".join(map(str, yolo_bbox)))\n",
    "                        f.write(\"\\n\")\n",
    "\n",
    "        list_of_videos.append(global_key)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466131ed-d753-4e32-8006-4fd72968d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_of_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5aa70-c67b-4a95-b276-1f265d478681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create yolov5 dataset configuration yaml\n",
    "import yaml\n",
    "\n",
    "project_root = Path(\"/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/whoi-rsi-fish-detection-yolo-dataset/\")\n",
    "train_split_filename = \"train_species_split.txt\"\n",
    "val_split_filename = \"val_species_split.txt\"\n",
    "test_split_filename = \"test_species_split.txt\"\n",
    "dataset_yaml_filename = \"fish_species_yolo_dataset.yaml\"\n",
    "\n",
    "if species_level:\n",
    "    names = dict(zip(classes_enum.values(), classes_enum.keys()))\n",
    "else:\n",
    "    names = {0: \"fish\"}\n",
    "\n",
    "yolo_dataset = {\n",
    "    \"path\": str(project_root),\n",
    "    \"train\": f\"./{train_split_filename}\",\n",
    "    \"val\": f\"./{val_split_filename}\",\n",
    "    \"test\": f\"./{test_split_filename}\",\n",
    "    \"names\": names,\n",
    "}\n",
    "yaml_data = yaml.dump(yolo_dataset)\n",
    "with open(project_root / dataset_yaml_filename, \"w\") as f:\n",
    "    f.write(yaml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7239b-36bd-4a86-8e72-7cd88aef2f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, val, and test splits\n",
    "open(project_root / train_split_filename, \"w\")\n",
    "open(project_root / val_split_filename, \"w\")\n",
    "open(project_root / test_split_filename, \"w\")\n",
    "\n",
    "import glob\n",
    "\n",
    "# Test split contains only years 2016 and 2017, these dates are inferred from the global_key\n",
    "img_paths = glob.iglob(str(project_root / \"**/*.png\"), recursive=True)\n",
    "\n",
    "# Note: this only adds images that have corresponding labels\n",
    "split_stats = {}\n",
    "split_stats[\"num_train_frames\"] = 0\n",
    "split_stats[\"num_val_frames\"] = 0\n",
    "split_stats[\"num_test_frames\"] = 0\n",
    "\n",
    "\n",
    "for img_path in tqdm(img_paths):\n",
    "    # Get relative path starting at project root\n",
    "    project_root_parts = len(project_root.parts)\n",
    "\n",
    "    frame_path = Path(*Path(img_path).parts[project_root_parts+1:])\n",
    "    project_img_path = \"images\" / frame_path\n",
    "    \n",
    "    vid_path = project_img_path.parent\n",
    "    \n",
    "    if not (project_root / \"labels\" / frame_path.with_suffix(\".txt\")).exists():\n",
    "        continue\n",
    "    \n",
    "    with open(project_root / \"video_list.txt\", \"a\") as f:\n",
    "        f.write(str(vid_path) + \"\\n\")\n",
    "        \n",
    "    # Test split\n",
    "    if \"2016\" in str(project_img_path) or \"2017\" in str(project_img_path):\n",
    "        with open(project_root / test_split_filename, \"a\") as f:\n",
    "            f.write(\"./\" + str(project_img_path) + \"\\n\")\n",
    "        split_stats[\"num_test_frames\"] += 1\n",
    "            \n",
    "    # Val split\n",
    "    elif \"2018\" in str(project_img_path):\n",
    "        with open(project_root / val_split_filename, \"a\") as f:\n",
    "            f.write(\"./\" + str(project_img_path) + \"\\n\")\n",
    "        split_stats[\"num_val_frames\"] += 1\n",
    "    \n",
    "    # Train split\n",
    "    else:\n",
    "        with open(project_root / train_split_filename, \"a\") as f:\n",
    "            f.write(\"./\" + str(project_img_path) + \"\\n\")\n",
    "        split_stats[\"num_train_frames\"] += 1\n",
    "        \n",
    "print(\"done\")\n",
    "print(split_stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
