{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b09b54e-5c19-4f06-a163-d13a73664cc0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Takes in YOLO dataset and produces a cropped images dataset with species-level classifications\n",
    "!pip install opencv-python\n",
    "\n",
    "# yolo_images_root = Path(\"/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/whoi-rsi-fish-detection-species-yolo-dataset/images\")\n",
    "# yolo_labels_root = Path(\"/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/whoi-rsi-fish-detection-species-yolo-dataset/labels\")\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa73fe-b925-4b87-9989-07333364ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotation(annotation_file):\n",
    "    with open(annotation_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    annotations = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        class_id = int(parts[0])\n",
    "        x_center = float(parts[1])\n",
    "        y_center = float(parts[2])\n",
    "        width = float(parts[3])\n",
    "        height = float(parts[4])\n",
    "        annotations.append((class_id, x_center, y_center, width, height))\n",
    "    return annotations\n",
    "\n",
    "def yolo2cv_bbox(yolo_bbox, width, height):\n",
    "    class_id, x_center, y_center, box_width, box_height = yolo_bbox\n",
    "    x_min = int((x_center - box_width / 2) * width)\n",
    "    x_max = int((x_center + box_width / 2) * width)\n",
    "    y_min = int((y_center - box_height / 2) * height)\n",
    "    y_max = int((y_center + box_height / 2) * height)\n",
    "    return (x_min, x_max, y_min, y_max)\n",
    "\n",
    "def annotate_image(image_dir, image_rel_path, annotation, output_dir):\n",
    "    image = cv2.imread(os.path.join(image_dir, image_rel_path))\n",
    "    val_image = image.copy()\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    for i, annot in enumerate(annotation):\n",
    "        x_min, x_max, y_min, y_max = yolo2cv_bbox(annot, width, height)\n",
    "        val_image = cv2.rectangle(val_image, (x_min, y_min), (x_max, y_max), (0,0,255), 2)\n",
    "\n",
    "    output_path = os.path.join(output_dir, image_rel_path)\n",
    "    os.makedirs(Path(output_path).parent, exist_ok=True)\n",
    "    cv2.imwrite(output_path, val_image)\n",
    "\n",
    "def crop_image(image_dir, image_rel_path, annotations, output_dir, crop_square=True):\n",
    "    image = cv2.imread(os.path.join(image_dir, image_rel_path))\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    for i, (class_id, x_center, y_center, box_width, box_height) in enumerate(annotations):\n",
    "        x_min = int((x_center - box_width / 2) * width)\n",
    "        x_max = int((x_center + box_width / 2) * width)\n",
    "        y_min = int((y_center - box_height / 2) * height)\n",
    "        y_max = int((y_center + box_height / 2) * height)\n",
    "\n",
    "        cropped_image = image[y_min:y_max, x_min:x_max, :]\n",
    "        output_path = os.path.join(output_dir, f\"{os.path.splitext(image_rel_path)[0]}_crop_{i}_class{class_id}.png\")\n",
    "        os.makedirs(Path(output_path).parent, exist_ok=True)\n",
    "        cv2.imwrite(output_path, cropped_image)\n",
    "\n",
    "def process_yolo_dataset(image_dir, annotation_dir, output_dir, img_type=\".png\", validation_dir=None):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    img_paths = glob.glob(os.path.join(image_dir,f\"**/*{img_type}\"), recursive=True)\n",
    "\n",
    "    for image_file in tqdm(img_paths):\n",
    "        image_rel_path = os.path.relpath(image_file, image_dir)\n",
    "        annotation_file = os.path.join(annotation_dir, os.path.splitext(image_rel_path)[0] + '.txt')\n",
    "\n",
    "        if os.path.exists(annotation_file):\n",
    "            annotations = parse_annotation(annotation_file)\n",
    "            crop_image(image_dir, image_rel_path, annotations, output_dir)\n",
    "            annotate_image(image_dir, image_rel_path, annotations, validation_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2f76f-b09e-40a4-b686-63df7bc3c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the crop extraction        \n",
    "# Example usage\n",
    "# image_directory = '/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/whoi-rsi-fish-detection-species-yolo-dataset/images'\n",
    "# annotation_directory = '/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/whoi-rsi-fish-detection-species-yolo-dataset/labels'\n",
    "# output_directory = '/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/whoi-rsi-fish-detection-species-classification-dataset/'\n",
    "# validation_output_directory = '/srv/warplab/shared/datasets/WHOI_RS_Fish_Detector/whoi-rsi-fish-detection-species-classification-dataset-validation'\n",
    "\n",
    "image_directory = '/media/data/warp_data/wrsi-datasets/whoi-rsi-fish-detection-species-yolo-dataset/images'\n",
    "annotation_directory = '/media/data/warp_data/wrsi-datasets/whoi-rsi-fish-detection-species-yolo-dataset/labels'\n",
    "output_directory = '/media/data/warp_data/wrsi-datasets/whoi-rsi-fish-detection-species-crops-dataset'\n",
    "validation_output_directory = '/media/data/warp_data/wrsi-datasets/whoi-rsi-fish-detection-species-validations'\n",
    "\n",
    "process_yolo_dataset(image_directory, annotation_directory, output_directory, validation_dir=validation_output_directory)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d347d254-4553-408d-92e9-b16eb3de28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import labelbox as lb\n",
    "import labelbox.types as lb_types\n",
    "import uuid\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "# Setup Labelbox naming and ID schemes\n",
    "\n",
    "# Setup client\n",
    "with open(\"labelbox_api_key.txt\",\"r\") as f:\n",
    "    API_KEY = f.read().strip()\n",
    "client = lb.Client(api_key=API_KEY)\n",
    "\n",
    "# Get ontology\n",
    "print(\"===ONTOLOGY DETAILS===\")\n",
    "ontology = client.get_ontology(\"clqo6bd8v0jc407ybc1r9ehlb\")\n",
    "print(\"Name: \", ontology.name)\n",
    "tools = ontology.tools()\n",
    "\n",
    "# for tool in tools:\n",
    "#   print(tool)\n",
    "\n",
    "# Get project\n",
    "print(\"\\n===PROJECT DETAILS===\")\n",
    "PROJECT_ID = 'clqoh3ylw1o8s070hd6ch5z7o' # WHOI RSI USVI Fish\n",
    "# PROJECT_ID = 'clqo7auln0mpo07wphorp0t2e' # Test WHOI RSI USVI Fish\n",
    "project = client.get_project(PROJECT_ID)\n",
    "print(\"Name: \", project.name)\n",
    "\n",
    "# Get dataset\n",
    "DATASET_ID = \"clqh7v7qi001r07886j6aws7i\"\n",
    "dataset = client.get_dataset(DATASET_ID)\n",
    "print(\"\\n===DATASET DETAILS===\")\n",
    "print(\"Name: \", dataset.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323378a0-dd60-4d07-a574-75ea0c9eb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate species labels for YOLO class formatting\n",
    "classes_option = {}\n",
    "classes_enum = {}\n",
    "ordered_class_names = []\n",
    "\n",
    "classes_option[\"fish\"] = {\"label\": \"Fish\", \"value\": \"fish\"}\n",
    "classes_enum[\"fish\"] = 0\n",
    "ordered_class_names.append(\"fish\")\n",
    "\n",
    "for option_num, option in enumerate(tools[0].classifications[0].options):\n",
    "    classes_option[option.value] = option\n",
    "    classes_enum[option.value] = len(ordered_class_names)\n",
    "    ordered_class_names.append(option.value)\n",
    "print(ordered_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc185e9-1964-4a12-b85d-26ea61c5983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print class-based statistics and their corresponding names\n",
    "# (What size, how many of each)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "cls_counts = [0]*len(ordered_class_names)\n",
    "\n",
    "cls_images = dict(zip(ordered_class_names,[[] for _ in range(len(ordered_class_names))]))\n",
    "\n",
    "def crop_stats(image_dir, img_type=\".png\"):\n",
    "    img_paths = glob.glob(os.path.join(image_dir,f\"**/*{img_type}\"), recursive=True)\n",
    "\n",
    "    for img_path in tqdm(img_paths):\n",
    "        pth = Path(img_path)\n",
    "        img_stem = pth.stem\n",
    "\n",
    "        # Assumes filename format: frame_<num>_crop_<instance num>_class<id>.png\n",
    "        cls_id = int(img_stem.split(\"class\")[-1])\n",
    "        cls_counts[cls_id] += 1\n",
    "\n",
    "        cls_name = ordered_class_names[cls_id]\n",
    "        \n",
    "        cls_images[cls_name].append(img_path)\n",
    "\n",
    "crops_directory = '/media/data/warp_data/wrsi-datasets/whoi-rsi-fish-detection-species-crops-dataset'\n",
    "\n",
    "crop_stats(crops_directory)\n",
    "\n",
    "cls_counts_list = list(zip(ordered_class_names, cls_counts))\n",
    "cls_counts_list = sorted(cls_counts_list, key=lambda x: x[1], reverse=True)\n",
    "print(cls_counts_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3a737-c816-48e7-aef6-1f5eaf04d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the crops of a particular class\n",
    "!pip install torchvision\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "def grid_from_crop_paths(crop_paths, output_path = None, img_transforms = None, output_img_size = (144,144), display_image = False):\n",
    "    \"\"\"\n",
    "    Loads and merges list of image paths into image grid and save them, where images may not be the same size. Provided transform must output the same size image though.\n",
    "    \"\"\"\n",
    "    if len(crop_paths) == 0:\n",
    "        return\n",
    "    \n",
    "    # Compose transforms\n",
    "    if img_transforms is None:\n",
    "        img_transforms = transforms.Compose([transforms.Resize(output_img_size)])\n",
    "\n",
    "    # Load and standardize images\n",
    "    imgs = []\n",
    "    for img_path in img_paths:\n",
    "        try:\n",
    "            img = read_image(img_path)\n",
    "        except:\n",
    "            print(\"Error reading: \", img_path)\n",
    "            continue\n",
    "        img = img_transforms(img)\n",
    "        imgs.append(img)\n",
    "\n",
    "    # Make grid\n",
    "    grid = make_grid(imgs)\n",
    "\n",
    "    # Show grid\n",
    "    if display_image:\n",
    "        show(grid)\n",
    "\n",
    "    # Save grid\n",
    "    if output_path:\n",
    "        grid = grid.permute(1, 2, 0).numpy() \n",
    "        #grid = (grid * 255).astype(np.uint8)\n",
    "        plt.imsave(output_path, grid)\n",
    "    \n",
    "    return grid\n",
    "\n",
    "# Make all the grid images for each class\n",
    "class_grids_directory = \"/media/data/warp_data/wrsi-datasets/whoi-rsi-fish-detection-species-crops-validation-grids\"\n",
    "os.makedirs(class_grids_directory, exist_ok=True)\n",
    "\n",
    "for cls_name, cls_count in tqdm(cls_counts_list):\n",
    "    if cls_count > 0:\n",
    "        # Get image paths\n",
    "        img_paths = cls_images[cls_name]\n",
    "            \n",
    "        # Save the gridded images\n",
    "        gridded_img_output_directory = class_grids_directory\n",
    "        gridded_img_name = f\"grid_{len(img_paths)}_\" + cls_name + f\".png\"\n",
    "        gridded_img_path = os.path.join(gridded_img_output_directory, gridded_img_name)\n",
    "\n",
    "        grid_from_crop_paths(img_paths, output_path = gridded_img_path)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e766dd77-664a-4b50-957d-3b9f7b8da7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
