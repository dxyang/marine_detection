{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff283efe-64f9-4b08-a199-ecb5cd8f97e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import json\n",
    "import jsonlines\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a289f105-53ff-4ed8-ade7-90b36e5f885b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_root = Path(\"/media/data/warp_data/marine_detection/imerit/whoi-rsi-fish-detection-datasets-22122023\")\n",
    "dataset_root = Path(\"/media/data/warp_data/marine_detection/imerit/whoi-rsi-fish-detection-datasets-22122023\")\n",
    "\n",
    "annotations_dir = dataset_root / \"annotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b2fd281-3ab6-4965-bdd3-781331c3ed09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    }
   ],
   "source": [
    "annotation_files = glob.glob(f\"{annotations_dir}/consolidated-annotation/output/*/*.json\")\n",
    "print(len(annotation_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e59c72ec-3fc5-4a60-8c14-3c1745dc8362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "manifest_json = dataset_root / \"28102023_manifest.json\"\n",
    "key_to_video_dir = {}\n",
    "with jsonlines.open(manifest_json) as reader:\n",
    "    for line_num, line in enumerate(reader):\n",
    "        seq_id = Path(line['source-ref'])\n",
    "        frame_folder = Path(str(seq_id.parent).replace(\"s3:/whoi-rsi-fish-detection/datasets/imerit_26102023_clips\", str(dataset_root)))\n",
    "        key_to_video_dir[line_num] = frame_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7030c83e-72a3-4f2b-9a7f-de5254b6e2de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coco_images = []\n",
    "coco_annotations = []\n",
    "video_sequences = []\n",
    "object_tracks = []\n",
    "\n",
    "img_num = 0\n",
    "ann_id = 0\n",
    "video_id = 0\n",
    "tracklet_id = 0\n",
    "\n",
    "do_viz = False\n",
    "read_frame_from_disk = False or do_viz\n",
    "img_w = 1920\n",
    "img_h = 1080\n",
    "expected_last_frame = 89\n",
    "\n",
    "for file_num, a_f in enumerate(annotation_files):\n",
    "    with jsonlines.open(a_f) as reader:\n",
    "        vid_num = int(Path(a_f).parent.name)\n",
    "        vid_dir = key_to_video_dir[vid_num]\n",
    "\n",
    "        for check, video_seq in enumerate(reader):\n",
    "            assert check == 0 # each json just has one long line\n",
    "                \n",
    "            num_frames_with_annotations = len(video_seq['tracking-annotations'])\n",
    "            video_frame_list = []\n",
    "            tracklets = {}\n",
    "\n",
    "            last_frame_num = -1\n",
    "            for ann_frame_num, per_frame in enumerate(video_seq['tracking-annotations']):\n",
    "                # keys: (['annotations', 'frame-no', 'frame', 'frame-attributes'])\n",
    "                # ann_frame_num may run from 0 to a number less than  or equal to 89\n",
    "                # frame-no here corresponds to the frame number 0 to 89 inclusive\n",
    "                # frame is the frame_%6d.png file name\n",
    "                annotations = per_frame['annotations']\n",
    "                frame_num = int(per_frame['frame-no'])\n",
    "                frame_str = per_frame['frame']\n",
    "\n",
    "                # sometimes we go a frame with no annotations. we should...\n",
    "                if last_frame_num != frame_num - 1:\n",
    "                    # 1. create empty images in COCO dataset\n",
    "                    while last_frame_num < frame_num - 1:\n",
    "                        frame_path = vid_dir / f'frame_{last_frame_num + 1:03d}.png'\n",
    "                        if read_frame_from_disk:\n",
    "                            img_bgr = cv2.imread(str(frame_path))\n",
    "                            img_h, img_w, img_c = img.shape \n",
    "                        else:\n",
    "                            assert os.path.exists(str(frame_path))\n",
    "                        dataset_relative_path = frame_path.relative_to(dataset_root)\n",
    "                        coco_images.append({\n",
    "                            \"id\": img_num, \n",
    "                            \"width\": img_w, \n",
    "                            \"height\": img_h, \n",
    "                            \"file_name\": str(dataset_relative_path), \n",
    "                            \"license\": 0,\n",
    "                            \"date_captured\": \"\",\n",
    "                        })\n",
    "                        video_frame_list.append(img_num)\n",
    "                        img_num += 1\n",
    "                        last_frame_num += 1\n",
    "                        \n",
    "                    # 2. delete all live fish\n",
    "                    pass\n",
    "\n",
    "                # yay process current frame\n",
    "                frame_path = vid_dir / per_frame['frame']\n",
    "                if read_frame_from_disk:\n",
    "                    img_bgr = cv2.imread(str(frame_path))\n",
    "                    img_h, img_w, img_c = img.shape\n",
    "                else:\n",
    "                    assert os.path.exists(str(frame_path)), str(frame_path)\n",
    "                dataset_relative_path = frame_path.relative_to(dataset_root)\n",
    "                coco_images.append({\n",
    "                    \"id\": img_num, \n",
    "                    \"width\": img_w, \n",
    "                    \"height\": img_h, \n",
    "                    \"file_name\": str(dataset_relative_path), \n",
    "                    \"license\": 0,\n",
    "                    \"date_captured\": \"\",\n",
    "                })\n",
    "\n",
    "                for fish in annotations:\n",
    "                    #keys: (['height', 'width', 'top', 'left', 'class-id', 'label-category-attributes', 'object-id', 'object-name'])\n",
    "                    x,y,w,h = fish['left'], fish['top'], fish['width'], fish['height']\n",
    "                    obj_id = fish['object-id']\n",
    "                    obj_name = fish['object-name']\n",
    "                    area = fish['height'] * fish['width']\n",
    "\n",
    "                    '''\n",
    "                    data parsing\n",
    "                    '''\n",
    "                    coco_annotations.append({\n",
    "                       \"id\": ann_id,\n",
    "                       \"image_id\": img_num,\n",
    "                       \"category_id\": 1, # fish\n",
    "                       \"bbox\": [x, y, w, h],\n",
    "                       \"area\": area,\n",
    "                       \"iscrowd\": 0\n",
    "                    })\n",
    "                    if obj_id in tracklets:\n",
    "                        tracklets[obj_id].append(ann_id)\n",
    "                    else:\n",
    "                        tracklets[obj_id] = [ann_id]\n",
    "                    ann_id += 1\n",
    "                    \n",
    "                    '''\n",
    "                    visualization\n",
    "                    '''\n",
    "                    if do_viz:\n",
    "                        # viz params\n",
    "                        color = (0, 0, 255)\n",
    "                        text_color = (255, 255, 255)\n",
    "                        text_size = 2.0\n",
    "                        text_width = 2\n",
    "                        \n",
    "                        # bounding box\n",
    "                        cv2.rectangle(img_bgr, (int(x), int(y)), (int(x+w), int(y+h)), color, 5)\n",
    "    \n",
    "                        # text\n",
    "                        (tw, th), _ = cv2.getTextSize(obj_name, cv2.FONT_HERSHEY_SIMPLEX, text_size, text_width)\n",
    "                        \n",
    "                        # Prints the text.    \n",
    "                        cv2.rectangle(img_bgr, (x, y - int(th * 1.5)), (x + tw, y), color, -1)\n",
    "                        cv2.putText(img_bgr, obj_name, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, text_size, text_color, text_width)\n",
    "                        \n",
    "                        # For printing text\n",
    "                        cv2.putText(img, 'test', (x, y), cv2.FONT_HERSHEY_SIMPLEX, text_size, (255,255,255), 1)\n",
    "\n",
    "                if do_viz:\n",
    "                    # visualization\n",
    "                    print(f\"Frame number: {frame_num}\")\n",
    "                    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "                    plt.figure()\n",
    "                    plt.imshow(img_rgb)\n",
    "\n",
    "                    if ann_frame_num >= 9:\n",
    "                        break\n",
    "\n",
    "                # bookkeeping\n",
    "                video_frame_list.append(img_num)\n",
    "                img_num += 1\n",
    "                last_frame_num = frame_num\n",
    "\n",
    "            # sometimes, the last image doesn't have an annotation\n",
    "            while last_frame_num < expected_last_frame:\n",
    "                frame_path = vid_dir / f'frame_{last_frame_num + 1:03d}.png'\n",
    "                if read_frame_from_disk:\n",
    "                    img_bgr = cv2.imread(str(frame_path))\n",
    "                    img_h, img_w, img_c = img.shape \n",
    "                else:\n",
    "                    assert os.path.exists(str(frame_path))\n",
    "                dataset_relative_path = frame_path.relative_to(dataset_root)\n",
    "                coco_images.append({\n",
    "                    \"id\": img_num, \n",
    "                    \"width\": img_w, \n",
    "                    \"height\": img_h, \n",
    "                    \"file_name\": str(dataset_relative_path), \n",
    "                    \"license\": 1,\n",
    "                    \"date_captured\": \"\",\n",
    "                })\n",
    "                video_frame_list.append(img_num)\n",
    "                img_num += 1\n",
    "                last_frame_num += 1\n",
    "\n",
    "            # per video bookkeeping\n",
    "            viddir_rel_dset_root = vid_dir.relative_to(dataset_root)\n",
    "            assert len(video_frame_list) == 90\n",
    "            video_sequences.append({\n",
    "                \"id\": video_id,\n",
    "                \"image_id_list\": video_frame_list,\n",
    "                \"file_name\": str(viddir_rel_dset_root),\n",
    "            })\n",
    "\n",
    "            for obj_id, bbox_id_seq in tracklets.items():\n",
    "                for bbox_id in bbox_id_seq:\n",
    "                    assert bbox_id == coco_annotations[bbox_id][\"id\"]\n",
    "                    \n",
    "                object_tracks.append({\n",
    "                    \"id\": tracklet_id,\n",
    "                    \"bbox_id_list\": bbox_id_seq,\n",
    "                    \"image_id_list\": [coco_annotations[bbox_id][\"image_id\"] for bbox_id in bbox_id_seq],\n",
    "                    \"video_seq_id\": video_id,\n",
    "                    \"category_id\": 1, # fish\n",
    "                })\n",
    "                tracklet_id += 1\n",
    "            video_id += 1\n",
    "\n",
    "        if do_viz:\n",
    "            print(f\"only visualizing first 10 annotated frames on first video...\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b14e6cb-c859-48ae-a9b7-79874c0eff76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved json to /media/data/warp_data/marine_detection/imerit/whoi-rsi-fish-detection-datasets-22122023/coco.json\n"
     ]
    }
   ],
   "source": [
    "coco_info = {\n",
    "    \"year\": 2023, \n",
    "    \"version\": \"1.0\", \n",
    "    \"description\": \"whoi-rsi-fish-detection\", \n",
    "    \"contributor\": \"WHOI RSI\", \n",
    "    \"url\": \"warp.whoi.edu\", \n",
    "    \"date_created\": datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\"),\n",
    "}\n",
    "coco_license = {\n",
    "        \"url\": \"TBD\", \n",
    "        \"id\": 1, \n",
    "        \"name\": \"TBD\"\n",
    "}\n",
    "coco_categories = [\n",
    "    {\"supercategory\": \"fish\", \"id\": 1, \"name\": \"fish\"},\n",
    "]\n",
    "\n",
    "'''\n",
    "info: Dict\n",
    "\n",
    "licenses: List[Dict]\n",
    "\n",
    "images: List[Dict]\n",
    "    \"id\": int,                      // unique for every image\n",
    "    \"width\": int, \n",
    "    \"height\": int, \n",
    "    \"file_name\": str,               // dataset relative path to image\n",
    "    \"license\": int,\n",
    "    \"date_captured\": str,\n",
    "\n",
    "annotations: List[Dict]\n",
    "    \"id\": int,                      // unique for every annotation      \n",
    "    \"image_id\": int,           \n",
    "    \"category_id\": int,             // 1 = fish, not sure how to consider hierarchies yet but COCO has supercategories for depth 1 trees\n",
    "    \"bbox\": List[int],              // [x, y, w, h]  \n",
    "    \"area\": int,                    // w * h\n",
    "    \"iscrowd\": int\n",
    "\n",
    "categories: List[Dict]\n",
    "\n",
    "video_sequences: List[Dict]\n",
    "    \"id\": int,                      // unique for every video sequence\n",
    "    \"image_id_list\": List[int],     // list of ids of images\n",
    "    \"file_name\": str,               // dataset relative path to image directory corresponding to video\n",
    "\n",
    "object_tracks: List[Dict]\n",
    "    \"id\": int,                      // unique for every video sequence\n",
    "    \"bbox_id_list\": List[int],      // list of ids of bboxes\n",
    "    \"image_id_list\": List[int],     // list of ids of images, maybe redundant (bboxes are each associated with an image)\n",
    "    \"video_seq_id\": int,            // maybe redundant (video_sequences has list of image ids)\n",
    "    \"category_id\": int,             // maybe redundant (each bbox already has a category)\n",
    "'''\n",
    "coco_fmt_dataset = {\n",
    "    \"info\": coco_info,\n",
    "    \"licenses\": [coco_license], \n",
    "    \"images\": coco_images,\n",
    "    \"annotations\": coco_annotations,\n",
    "    \"categories\": coco_categories,\n",
    "    \"video_sequences\": video_sequences,\n",
    "    \"object_tracks\": object_tracks,\n",
    "}\n",
    "coco_json_path = dataset_root/ \"coco.json\"\n",
    "with open(coco_json_path, 'w') as f:\n",
    "    json.dump(coco_fmt_dataset, f, indent=4)\n",
    "print(f\"saved json to {coco_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f0af10-5563-4913-ae52-8829625945b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cbfcd-5dcf-4979-9e72-736594f2b390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcd2cb-50db-461f-b16b-0c6f3e7a3ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
