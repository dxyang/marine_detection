{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fcb9130-5c2d-419b-90fe-ae90f3e8ee51",
   "metadata": {},
   "source": [
    "## Create motion-based datasets from a Labelbox-style or COCO-style dataset\n",
    "\n",
    "Types of datasets:\n",
    "- Grids of crops of individual tracklets (grid-crops)\n",
    "- On last image of tracklets, plot the past trajectories (traj-line-plots)\n",
    "- On black background, plot all crops of the trajectory (traj-crop-plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0aa492-d775-4885-8a9c-6cb9ad2ce6b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global settings and datasets\n",
    "\n",
    "# Labelbox dataset:\n",
    "# labelbox_json = \"/media/data/warp_data/wrsi-datasets/Labelbox-Export-WHOI-RSI-USVI-Fish-detect-and-track - 6_11_2024.ndjson\"\n",
    "# image_root_dir = \"/media/data/warp_data/wrsi-datasets/whoi-rsi-fish-detection-yolo-dataset/images\"\n",
    "\n",
    "# COCO dataset:\n",
    "coco_json = \"/media/data/warp_data/marine_detection/imerit/whoi-rsi-fish-detection-datasets-22122023/coco.json\"\n",
    "image_root_dir = \"/media/data/warp_data/marine_detection/imerit/whoi-rsi-fish-detection-datasets-22122023/\"\n",
    "\n",
    "output_root_dir = \"/media/data/warp_data/wrsi-datasets/whoi-rsi-fish-motion-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287bc3a2-10e9-4eb4-b0e5-79332fd93659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Labelbox\n",
    "import labelbox as lb\n",
    "import labelbox.types as lb_types\n",
    "import uuid\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "LABELBOX_API_KEY = \"labelbox_api_key.txt\"\n",
    "ONTOLOGY_ID = \"clqo6bd8v0jc407ybc1r9ehlb\"\n",
    "PROJECT_ID = 'clqoh3ylw1o8s070hd6ch5z7o' # WHOI RSI USVI Fish Track and Detect\n",
    "DATASET_ID = \"clqh7v7qi001r07886j6aws7i\"\n",
    "\n",
    "# Setup client\n",
    "with open(LABELBOX_API_KEY,\"r\") as f:\n",
    "    API_KEY = f.read().strip()\n",
    "client = lb.Client(api_key=API_KEY)\n",
    "\n",
    "ontology = client.get_ontology(ONTOLOGY_ID)\n",
    "project = client.get_project(PROJECT_ID)\n",
    "dataset = client.get_dataset(DATASET_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7e7c2-8be1-4f86-85d9-f31aae669f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Local imports\n",
    "import labelbox_fish_utils as lbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7634ece-4a5c-4f36-9916-1f9c32ba2b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All annotations assumed to be in x, y, w, h format\n",
    "\n",
    "def crop_image(image_path, annotation, square_crop=True, resize=(244,244)):\n",
    "    img = cv2.imread(image_path)\n",
    "    x, y, w, h = annotation\n",
    "\n",
    "    if square_crop:\n",
    "        m = max(w,h)\n",
    "        cx = int(x + w/2)\n",
    "        cy = int(y + h/2)\n",
    "        crop = img[int(cy-h/2):int(cy+h/2), int(cx-w/2):int(cx+w/2), :]\n",
    "    else:\n",
    "        crop = img[y:y+h, x:x+w, :]\n",
    "\n",
    "    if resize:\n",
    "        crop = cv2.resize(crop, resize)\n",
    "    return crop\n",
    "\n",
    "def trajectory_image(image_paths, annotations, mode=\"crop\"):\n",
    "    \"\"\"\n",
    "    Inputs: An ordered list of images and annotations\n",
    "    Mode traj: Plots the previous bbox trajectories of the object on last image\n",
    "    Mode crop: Plots the previous crops on a black image, last one on top\n",
    "    \"\"\"\n",
    "    last_image_path = image_paths[-1]\n",
    "    last_image = cv2.imread(last_image_path)\n",
    "    \n",
    "    if mode == \"crop\":\n",
    "        base_image = np.zeros(last_image.shape)\n",
    "        \n",
    "    elif mode == \"traj\":\n",
    "        base_image = last_image.copy()\n",
    "\n",
    "        x, y, w, h = annotations[-1]\n",
    "        base_image = cv2.rectangle(base_image, (x, y), (x+w, y+h), color=(0,0,255), thickness=2)\n",
    "\n",
    "    for image_path, annotation in zip(image_paths, annotations):\n",
    "        x, y, w, h = annotation\n",
    "\n",
    "        if mode == \"traj\":\n",
    "            cx = int(x + w/2)\n",
    "            cy = int(y + h/2)\n",
    "            base_image = cv2.circle(base_image, (cx, cy), radius=2, color=(0,0,255), thickness=2) \n",
    "        \n",
    "        elif mode == \"crop\":\n",
    "            image = cv2.imread(image_path)\n",
    "            base_image[y:y+h,x:x+w] = image[y:y+h,x:x+w]\n",
    "\n",
    "    return base_image\n",
    "\n",
    "def generate_motion_dataset_from_labelbox(json_path, image_root_dir, output_root_dir):\n",
    "    # Iterate through every tracklet\n",
    "    pass\n",
    "\n",
    "def generate_motion_dataset_from_coco(coco_json_path, image_root_dir, output_root_dir):\n",
    "    \"\"\"\n",
    "    Generates a tracklet-based dataset from coco and image_root directory\n",
    "    If ordered is passed, will generate a separate folder consisting of grid images based on length of trajectories (and thus is sortable)\n",
    "\n",
    "    todo: rename ordered to traj_len_based or something\n",
    "    \"\"\"\n",
    "    # Parse COCO json\n",
    "    with open(coco_json_path, \"r\") as f:\n",
    "        coco = json.load(f)\n",
    "    \n",
    "    # Iterate through every object\n",
    "    for object_track in tqdm(coco[\"object_tracks\"]):\n",
    "        bbox_id_list = object_track[\"bbox_id_list\"]\n",
    "\n",
    "        bboxes = []\n",
    "        image_paths = []\n",
    "        crops = []\n",
    "        \n",
    "        # Get bounding boxes and images\n",
    "        for bbox_id in bbox_id_list:\n",
    "            \n",
    "            # Get bbox\n",
    "            annotation = coco[\"annotations\"][bbox_id]\n",
    "            bbox = annotation[\"bbox\"]\n",
    "\n",
    "            # Get image\n",
    "            image_id = annotation[\"image_id\"]\n",
    "            image = coco[\"images\"][image_id]\n",
    "            image_path = os.path.join(image_root_dir, image[\"file_name\"])\n",
    "\n",
    "            # Crop image\n",
    "            crop = crop_image(image_path, bbox, resize=(244,244))\n",
    "\n",
    "            bboxes.append(bbox)\n",
    "            crops.append(crop)\n",
    "            image_paths.append(image_path)\n",
    "\n",
    "        # Make an image grid\n",
    "        img_grid = np.hstack(crops)\n",
    "\n",
    "        # Comment/uncomment below to save certain types of outputs\n",
    "        traj_len = len(crops)\n",
    "        object_track_id = object_track[\"id\"]\n",
    "        output_dir_name = Path(output_root_dir).name\n",
    "        \n",
    "        # Save stacked image\n",
    "        # video_path = coco[\"video_sequences\"][object_track[\"video_seq_id\"]][\"file_name\"]\n",
    "        # output_dir_path = os.path.join(output_root_dir, video_path)\n",
    "        # os.makedirs(output_dir_path, exist_ok=True)\n",
    "        # output_path = os.path.join(output_dir_path, f\"{object_track['id']}.png\")\n",
    "        # cv2.imwrite(output_path, img_grid)\n",
    "\n",
    "        # Save grids to a sortable folder\n",
    "        # ordered_output_path = os.path.join(output_dir_path, \"../sortable_tracklets\", f\"traj_{traj_len}_obj_id_{object_track_id}.png\")\n",
    "        # cv2.imwrite(ordered_output_path, img_grid)\n",
    "        \n",
    "        # Save trajectory crop images\n",
    "        os.makedirs(os.path.join(output_root_dir, f\"../{output_dir_name}_traj_crop_images\"), exist_ok=True)\n",
    "        traj_crop_img = trajectory_image(image_paths, bboxes, mode=\"crop\")\n",
    "        traj_crop_output_path = os.path.join(output_root_dir, f\"../{output_dir_name}_traj_crop_images\", f\"traj_{traj_len}_{object_track_id}.png\")\n",
    "        cv2.imwrite(traj_crop_output_path, traj_crop_img)\n",
    "\n",
    "        # Save trajectory images\n",
    "        os.makedirs(os.path.join(output_root_dir, f\"../{output_dir_name}_traj_images\"), exist_ok=True)\n",
    "        traj_img = trajectory_image(image_paths, bboxes, mode=\"traj\")\n",
    "        traj_output_path = os.path.join(output_root_dir, f\"../{output_dir_name}_traj_images\", f\"traj_{traj_len}_{object_track_id}.png\")\n",
    "        cv2.imwrite(traj_output_path, traj_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f1422-6051-4d59-8b83-2c6778ed0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "generate_motion_dataset_from_coco(coco_json, image_root_dir, output_root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
